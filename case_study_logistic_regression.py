# -*- coding: utf-8 -*-
"""Case Study - Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1No-qk0eY-23Z2ByAgWfvrX-Y6dTIBHgY

## Problem Statement

One of the prestigious bank maintains a database of the customer and their details. Based on this dataset the requirememt is to create the classification model using Logistic Regression to predict if the customer will churn or not. There are around 10000 records using this we need to create the model after breaking the data into test and train.

**Data Dictionary**

**RowNumber** - Unique number

**CustomerID** - Unique Customer ID

**Surname** - Last name of the customer

**CreditScore** - Credit Score of the customer based on the past payments

**Geography** - Country of the customer

**Gender** - Gender of the customer

**Age** - Age of the customer

**Tenure** - Duration of the relationship with the customer

**Balance** - Bank balance of the customer

**NumOfProducts** - Total number of products customer opted for

**HasCrCard** - Has credit card or not

**IsActiveMember** - Is the customer is active or not

**EstimatedSalary** - Customer's estimated salary

**Exited** - Churn value

# Table of Content

1. **[Import Libraries](#lib)**
2. **[Data Preparation](#prep)**
    - 2.1 - **[Understand the Data](#read)**
    - 2.2 - **[Exploratory Data Analysis](#eda)**
    - 2.3 - **[Missing Value Treatment](#null)**
    - 2.4 - **[Encoding and Feature Scaling](#enc)**
3. **[What is Logistic Regression](#lr)**
    - 3.1 - **[Geometric Intuition](#gi)**
    - 3.2 - **[Mathematical Formulation](#mf)**
    - 3.3 - **[Sigmoid Function](#sf)**
4. **[Splitting the data into Train and Test](#sd)**
5. **[Creating the model on training dataset and understand the feature importance using the weights](#model)**
6. **[Run the model on the Test Dataset](#test)**
7. **[Check the accuracy of the model](#acc)**
    - 7.1 - **[Accuracy Score](#accscore)**
    - 7.2 - **[Confusion Matrix](#cm)**
    - 7.3 - **[ROC Curve](#roc)**
    - 7.4 - **[F1 Score](#f1score)**
    - 7.5 - **[Log Loss](#logloss)**
8. **[Comparing the Training and Testing Accuracies](#overunder)**

<a id="lib"></a>
# 1. Import Libraries
"""

#Importing the libraries which will be helpful for the data analysis.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_curve
from sklearn.metrics import accuracy_score
from matplotlib.colors import ListedColormap

"""<a id="prep"></a>
# 2. Data Preparation
"""

#Importing the dataset which we will use for the modelling
dataset = pd.read_csv('/content/Churn_Modelling.csv')

"""<a id="read"></a>
# 2.1. Understand the Data
"""

#Here are the few commands which will help us to understand the basic data
#The info command will help us to understand the different columns present in the dataset and its datatype
dataset.info()

#Len command will help us understand the total number of records present in the dataset
len(dataset)

"""**Removing insignificant variables**"""

# drop the column 'Serial No.' using drop()
# 'axis = 1' drops the specified column
dataset = dataset.drop(['RowNumber','CustomerId','Surname'], axis = 1)

#.columns command will help us understand the columns present in the dataset
dataset.columns

#The below command will help us understand the total number of columns present in the dataset
len(dataset.columns)

"""<a id="eda"></a>
# 2.2. Exploratory Data Analysis
"""

plt.figure(figsize=(15,2))
sns.countplot(data=dataset, x = 'Geography',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that Geography is an important variable for predicting the churn rate**"""

plt.figure(figsize=(15,2))
sns.countplot(data=dataset, x = 'Gender',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that Gender is an important variable for predicting the churn rate**"""

plt.figure(figsize=(15,2))
sns.histplot(data=dataset, x = 'Age',hue='Exited')
plt.show()

"""**From the above chart we can say that customers with lower age are more loyal to the company**"""

plt.figure(figsize=(15,2))
sns.histplot(data=dataset, x = 'Tenure',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that Tenure is an important variable for predicting the churn rate**"""

plt.figure(figsize=(15,2))
sns.histplot(data=dataset, x = 'CreditScore',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that Credit Score is an important variable for predicting the churn rate**"""

plt.figure(figsize=(15,2))
sns.histplot(data=dataset, x = 'Balance',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that Balance is an important variable for predicting the churn rate**"""

plt.figure(figsize=(15,2))
sns.countplot(data=dataset, x = 'NumOfProducts',hue='Exited')
plt.show()

"""**From the above chart we can say that people with higher number of products are more tend to leave the company**"""

plt.figure(figsize=(15,2))
sns.countplot(data=dataset, x = 'HasCrCard',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that Has Credit Card is an important variable for predicting the churn rate**"""

plt.figure(figsize=(15,2))
sns.countplot(data=dataset, x = 'IsActiveMember',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that IsActiveMember is an important variable for predicting the churn rate**"""

plt.figure(figsize=(15,2))
sns.histplot(data=dataset, x = 'EstimatedSalary',hue='Exited')
plt.show()

"""**From the above chart there is no significant outcome which can tell us that Salary is an important variable for predicting the churn rate**

<a id="null"></a>
# 2.3. Missing Value Treatment
"""

#Checking the count of the missing values percentage, there are very few missing values there in the dataset
dataset.isnull().sum()/len(dataset)*100

# Separating the numerical and categorical columns

def data_type(dataset):
    """
    Function to identify the numerical and categorical data columns
    :param dataset: Dataframe
    :return: list of numerical and categorical columns
    """
    numerical = []
    categorical = []
    for i in dataset.columns:
        if dataset[i].dtype == 'int64' or dataset[i].dtype == 'float64':
            numerical.append(i)
        else:
            categorical.append(i)
    return numerical, categorical


numerical, categorical = data_type(dataset)

# Identifying the binary columns and ignoring them from scaling
def binary_columns(df):
    """
    Generates a list of binary columns in a dataframe.
    """
    binary_cols = []
    for col in df.select_dtypes(include=['int', 'float']).columns:
        unique_values = df[col].unique()
        if np.in1d(unique_values, [0, 1]).all():
            binary_cols.append(col)
    return binary_cols

binary_cols = binary_columns(dataset)

# Remove the binary columns from the numerical columns
numerical = [i for i in numerical if i not in binary_cols]

# Function to Impute the missing values
def missing_value_imputation(dataset, numerical, categorical):
    """
    Function to automate the process of missing value imputation
    :param dataset: Dataframe
    :param numerical: List of numerical columns
    :param categorical: List of categorical columns
    :return: Dataframe
    """
    for i in numerical:
        dataset[i] = dataset[i].fillna(dataset[i].median())
    for i in categorical:
        dataset[i] = dataset[i].fillna(dataset[i].mode()[0])
    return dataset

dataset = missing_value_imputation(dataset, numerical, categorical)

"""<a id="enc"></a>
# 2.4. Encoding and Feature Scaling
"""

# Separating the numerical and categorical columns
from sklearn.preprocessing import StandardScaler

def encoding(dataset, categorical):
    """
    Function to automate the process of encoding the categorical data
    :param dataset: Dataframe
    :param categorical: List of categorical columns
    :return: Dataframe
    """
    for i in categorical:
        dataset[i] = dataset[i].astype('category')
        dataset[i] = dataset[i].cat.codes
    return dataset

dataset = encoding(dataset, categorical)

def feature_scaling(dataset, numerical):
    """
    Function to automate the process of feature scaling the numerical data
    :param dataset: Dataframe
    :param numerical: List of numerical columns
    :return: Dataframe
    """
    sc_x = StandardScaler()
    dataset[numerical] = sc_x.fit_transform(dataset[numerical])
    return dataset

dataset = feature_scaling(dataset, numerical)

dataset

"""<a id="sd"></a>
# 4. Splitting the data into Train and Test
"""

x = dataset.iloc[:,0:10]

y = dataset.iloc[:,-1]

# add a constant column to the dataframe
# while using the 'Logit' method in the Statsmodels library, the method do not consider the intercept by default
# we can add the intercept to the set of independent variables using 'add_constant()'
x = sm.add_constant(x)

# split data into train subset and test subset
# set 'random_state' to generate the same dataset each time you run the code
# 'test_size' returns the proportion of data to be included in the testing set
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 10, test_size = 0.2)

# check the dimensions of the train & test subset using 'shape'
# print dimension of train set
print('X_train', x_train.shape)
print('y_train', y_train.shape)

# print dimension of test set
print('X_test', x_test.shape)
print('y_test', y_test.shape)

# create an empty dataframe to store the scores for various algorithms
score_card = pd.DataFrame(columns=['Probability Cutoff', 'AUC Score', 'Precision Score', 'Recall Score',
                                       'Accuracy Score', 'Kappa Score', 'f1-score'])

# append the result table for all performance scores
# performance measures considered for model comparision are 'AUC Score', 'Precision Score', 'Recall Score','Accuracy Score',
# 'Kappa Score', and 'f1-score'
# compile the required information in a user defined function
def update_score_card(model, cutoff):

    # let 'y_pred_prob' be the predicted values of y
    y_pred_prob = model.predict(x_test)

    # convert probabilities to 0 and 1 using 'if_else'
    y_pred = [ 0 if x < cutoff else 1 for x in y_pred_prob]

    # assign 'score_card' as global variable
    global score_card

    # append the results to the dataframe 'score_card'
    # 'ignore_index = True' do not consider the index labels
    score_card = score_card.append({'Probability Cutoff': cutoff,
                                    'AUC Score' : metrics.roc_auc_score(y_test, y_pred),
                                    'Precision Score': metrics.precision_score(y_test, y_pred),
                                    'Recall Score': metrics.recall_score(y_test, y_pred),
                                    'Accuracy Score': metrics.accuracy_score(y_test, y_pred),
                                    'Kappa Score':metrics.cohen_kappa_score(y_test, y_pred),
                                    'f1-score': metrics.f1_score(y_test, y_pred)},
                                    ignore_index = True)

"""<a id="model"></a>
# 5. Creating the model on training dataset and understand the feature importance using the weights
"""

# import various functions from statsmodels
import statsmodels
import statsmodels.api as sm
# build the model on train data (X_train and y_train)
# use fit() to fit the logistic regression model
logreg_ini = sm.Logit(y_train, x_train).fit()

# print the summary of the model
logreg_ini.summary()

"""**Interpretation:** The `Pseudo R-squ.` obtained from the above model summary is the value of `McFadden's R-squared`. This value can be obtained from the formula:

<p style='text-indent:25em'> <strong> McFadden's R-squared = $ 1 - \frac{Log-Likelihood}{LL-Null} $</strong> </p>

Where,<br>
Log-Likelihood: It is the maximum value of the log-likelihood function<br>
LL-Null: It is the maximum value of the log-likelihood function for the model containing only the intercept

The LLR p-value is less than 0.05, implies that the model is significant.
"""

from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve
from sklearn.metrics import accuracy_score

# 'aic' retuns the AIC value for the model
print('AIC:', logreg_ini.aic)

"""We can use the AIC value to compare different models created on the same dataset.

**Interpreting the odds**
"""

# take the exponential of the coefficient of a variable to calculate the odds
# 'params' returns the coefficients of all the independent variables
# pass the required column name to the parameter, 'columns'
df_odds = pd.DataFrame(np.exp(logreg_ini.params), columns= ['Odds'])

# print the dataframe
df_odds

"""**Interpretation:**

odds_const: The odds of churn is 0.445092, considering all other variables take zero value

odds_creditscore: The odds of chrun is increase by the factor of 0.949662 due to an unit increase of Credit score and keeping the other variables as constant

odds_geography: The odds of chrun is increase by the factor of 1.072893 due to a change in the geography

odds_gender: The odds of chrun is increase by the factor of 0.567264 due to an change in the gender

odds_Age: The odds of chrun is increase by the factor of 2.140222 due to an unit increase of age and keeping the other variables as constant

odds_tenure: The odds of chrun is increase by the factor of 0.982020 due to an unit increase of tenure and keeping the other variables as constant

odds_balance: The odds of chrun is increase by the factor of 0.949662 due to an unit increase of Credit score and keeping the other variables as constant

odds_noofproducts: The odds of chrun is increase by the factor of 1.365431 due to an unit increase of no of products and keeping the other variables as constant

odds_hascrcard: The odds of chrun is increase by the factor of 0.968417 due to card availability and keeping the other variables as constant

odds_isactivemember: The odds of chrun is increase by the factor of 0.333560 due to an activity by the user and keeping the other variables as constant

odds_esimatedsalary: The odds of chrun is increase by the factor of 1.039406 due to an unit increase of salary and keeping the other variables as constant
"""

# let 'y_pred_prob' be the predicted values of y
y_pred_prob = logreg_ini.predict(x_test)

# print the y_pred_prob
y_pred_prob.head()

# convert probabilities to 0 and 1 using 'if_else'
y_pred_ini = [ 0 if x < 0.5 else 1 for x in y_pred_prob]

# print the first five observations of y_pred
y_pred_ini[0:5]

#Using accuracy score we are checking the accuracy on the testing dataset
accuracy_score(y_test,y_pred_ini)

# create a confusion matrix
cm = confusion_matrix(y_test, y_pred_ini)
conf_matrix = pd.DataFrame(data = cm,columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])
sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = ListedColormap(['lightskyblue']), cbar = False,
            linewidths = 0.1, annot_kws = {'size':25})
plt.xticks(fontsize = 20)
plt.yticks(fontsize = 20)
plt.show()

# calculate various performance measures
acc_table = classification_report(y_test, y_pred_ini)

# print the table
print(acc_table)

# compute the kappa value
kappa = cohen_kappa_score(y_test, y_pred_ini)

# print the kappa value
print('kappa value:',kappa)

# the roc_curve() returns the values for false positive rate, true positive rate and threshold
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# plot the ROC curve
plt.plot(fpr, tpr)

# set limits for x and y axes
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])

# plot the straight line showing worst prediction for the model
plt.plot([0, 1], [0, 1],'r--')

plt.title('ROC curve for Admission Prediction Classifier (Full Model)', fontsize = 15)
plt.xlabel('False positive rate (1-Specificity)', fontsize = 15)
plt.ylabel('True positive rate (Sensitivity)', fontsize = 15)

plt.text(x = 0.02, y = 0.9, s = ('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred_prob),4)))

# plot the grid
plt.grid(True)

# consider a list of values for cut-off
#cutoff = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

# use the for loop to compute performance measures for each value of the cut-off
# call the update_score_card() to update the score card for each cut-off
# pass the model and cut-off value to the function
#for value in cutoff:
    #update_score_card(logreg_ini, value)

score_card

# print the score card
print('Score Card for Logistic regression:')

# sort the dataframe based on the probability cut-off values ascending order
# 'reset_index' resets the index of the dataframe
# 'drop = True' drops the previous index
score_card = score_card.sort_values('Probability Cutoff').reset_index(drop = True)

# color the cell in the columns 'AUC Score', 'Accuracy Score', 'Kappa Score', 'f1-score' having maximum values
# 'style.highlight_max' assigns color to the maximum value
# pass specified color to the parameter, 'color'
# pass the data to limit the color assignment to the parameter, 'subset'
score_card.style.highlight_max(color = 'lightblue', subset = ['AUC Score', 'Accuracy Score', 'Kappa Score', 'f1-score'])

"""**Removing statistically insignificant variables**"""

#Removing the insignificant variables
dataset

x = dataset.iloc[:,[2,3,5,8]]

# add a constant column to the dataframe
# while using the 'Logit' method in the Statsmodels library, the method do not consider the intercept by default
# we can add the intercept to the set of independent variables using 'add_constant()'
x = sm.add_constant(x)

# split data into train subset and test subset
# set 'random_state' to generate the same dataset each time you run the code
# 'test_size' returns the proportion of data to be included in the testing set
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 10, test_size = 0.2)

# check the dimensions of the train & test subset using 'shape'
# print dimension of train set
print('X_train', x_train.shape)
print('y_train', y_train.shape)

# print dimension of test set
print('X_test', x_test.shape)
print('y_test', y_test.shape)

# build the model on train data (X_train and y_train)
# use fit() to fit the logistic regression model
logreg_tuned = sm.Logit(y_train, x_train).fit()

# print the summary of the model
logreg_tuned.summary()

# 'aic' retuns the AIC value for the model
print('AIC:', logreg_tuned.aic)

# take the exponential of the coefficient of a variable to calculate the odds
# 'params' returns the coefficients of all the independent variables
# pass the required column name to the parameter, 'columns'
df_odds = pd.DataFrame(np.exp(logreg_tuned.params), columns= ['Odds'])

# print the dataframe
df_odds

"""**Interpretation:**

odds_const: The odds of churn is 0.460254, considering all other variables take zero value

odds_gender: The odds of chrun is increase by the factor of 0.567860 due to an change in the gender

odds_Age: The odds of chrun is increase by the factor of 2.141525 due to an unit increase of age and keeping the other variables as constant

odds_balance: The odds of chrun is increase by the factor of 1.382010 due to an unit increase of Credit score and keeping the other variables as constant

odds_isactivemember: The odds of chrun is increase by the factor of 0.332281 due to an activity by the user and keeping the other variables as constant
"""

# let 'y_pred_prob' be the predicted values of y
y_pred_prob = logreg_tuned.predict(x_test)

# print the y_pred_prob
y_pred_prob.head()

# convert probabilities to 0 and 1 using 'if_else'
y_pred_tuned = [ 0 if x < 0.5 else 1 for x in y_pred_prob]

# print the first five observations of y_pred
#y_pred[0:5]

# create a confusion matrix
cm = confusion_matrix(y_test, y_pred_tuned)

conf_matrix = pd.DataFrame(data = cm,columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])


sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = ListedColormap(['lightskyblue']), cbar = False,
            linewidths = 0.1, annot_kws = {'size':25})

plt.xticks(fontsize = 20)

plt.yticks(fontsize = 20)

plt.show()

# calculate various performance measures
acc_table = classification_report(y_test, y_pred_tuned)

# print the table
print(acc_table)

# compute the kappa value
kappa = cohen_kappa_score(y_test, y_pred_tuned)

# print the kappa value
print('kappa value:',kappa)

# the roc_curve() returns the values for false positive rate, true positive rate and threshold
# pass the actual target values and predicted probabilities to the function
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# plot the ROC curve
plt.plot(fpr, tpr)

# set limits for x and y axes
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])

# plot the straight line showing worst prediction for the model
plt.plot([0, 1], [0, 1],'r--')

# add plot and axes labels
# set text size using 'fontsize'
plt.title('ROC curve for Admission Prediction Classifier (Full Model)', fontsize = 15)
plt.xlabel('False positive rate (1-Specificity)', fontsize = 15)
plt.ylabel('True positive rate (Sensitivity)', fontsize = 15)

# add the AUC score to the plot
# 'x' and 'y' gives position of the text
# 's' is the text
# use round() to round-off the AUC score upto 4 digits
plt.text(x = 0.02, y = 0.9, s = ('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred_prob),4)))

# plot the grid
plt.grid(True)

# consider a list of values for cut-off
cutoff = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

# use the for loop to compute performance measures for each value of the cut-off
# call the update_score_card() to update the score card for each cut-off
# pass the model and cut-off value to the function
for value in cutoff:
    update_score_card(logreg_tuned, value)

# print the score card
print('Score Card for Logistic regression:')

# sort the dataframe based on the probability cut-off values ascending order
# 'reset_index' resets the index of the dataframe
# 'drop = True' drops the previous index
score_card = score_card.sort_values('Probability Cutoff').reset_index(drop = True)

# color the cell in the columns 'AUC Score', 'Accuracy Score', 'Kappa Score', 'f1-score' having maximum values
# 'style.highlight_max' assigns color to the maximum value
# pass specified color to the parameter, 'color'
# pass the data to limit the color assignment to the parameter, 'subset'
score_card.style.highlight_max(color = 'lightblue', subset = ['AUC Score', 'Accuracy Score', 'Kappa Score', 'f1-score'])

# create an empty dataframe to store the scores for various algorithms
from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_auc_score, f1_score
score_card = pd.DataFrame(columns=['model_name','Accuracy Score','Precision Score','Recall Score','AUC Score','f1 Score'])

# append the result table for all performance scores

def update_score_card_final(y_test,y_pred,model_name):

    # assign 'score_card' as global variable
    global score_card

    # append the results to the dataframe 'score_card'
    # 'ignore_index = True' do not consider the index labels
    score_card = score_card.append({'model_name':model_name,
                                    'Accuracy Score' : accuracy_score(y_test, y_pred),
                                    'Precision Score': precision_score(y_test, y_pred),
                                    'Recall Score': recall_score(y_test, y_pred),
                                    'AUC Score': roc_auc_score(y_test, y_pred),
                                    'f1 Score': f1_score(y_test, y_pred)},
                                    ignore_index = True)

update_score_card_final(y_test,y_pred_ini,'initial_model')

update_score_card_final(y_test,y_pred_tuned,'tuned_model')

score_card

"""**Interpretation: Overall we have implemented all the tuning steps and we can conclude that the model which we got is performing well on the dataset**"""